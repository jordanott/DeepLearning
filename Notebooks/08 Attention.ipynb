{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Attention\n",
    "\n",
    "<img src=\"https://www.azquotes.com/picture-quotes/quote-i-tried-to-pay-attention-but-attention-paid-me-lil-wayne-63-4-0430.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Speech Recognition\n",
    "<img src=\"https://colinraffel.com/blog/images/mad/las_alignments.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image Captioning\n",
    "![](https://velement.io/wp-content/uploads/2018/03/Screen-Shot-2014-11-17-at-2.11.11-PM-730x471.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Language Translation\n",
    "![](https://smerity.com/media/images/articles/2016/gnmt_arch_1_enc_dec.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sequence to Sequence Translation Steps\n",
    "* Use an encoder network (LSTM) \n",
    "* Compress input sequence to a single vector **S**\n",
    "* Use a second decoder network (LSTM)\n",
    "* Produce translations from input to output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://lilianweng.github.io/lil-log/assets/images/encoder-decoder-example.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<video width=100% controls src=\"http://jalammar.github.io/images/seq2seq_4.mp4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What's Wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**“You can't cram the meaning of a whole \\*%&!ing sentence into a single \\$&!*ing vector!”** Ray Mooney"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Question Answering Example\n",
    "![](https://cdn-images-1.medium.com/max/1600/0*t06Bz1SOcsUGEIVj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Attention\n",
    "* Use context when answering\n",
    "* 'Attend' to areas of interest\n",
    "* Should allow our neural networks to do the same  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<video width=100% controls src=\"http://jalammar.github.io/images/attention_tensor_dance.mp4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<video width=100% controls src=\"http://jalammar.github.io/images/attention_process.mp4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Attention Weights\n",
    "![](https://lilianweng.github.io/lil-log/assets/images/encoder-decoder-attention.png)\n",
    "[Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Definition\n",
    "* Input sequence $x$\n",
    "* Target sequence $y$  \n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathbf{x} &= [x_1, x_2, \\dots, x_n] \\\\\n",
    "\\mathbf{y} &= [y_1, y_2, \\dots, y_m]\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Hidden state of recurrent encoder network, $h_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decoder Network\n",
    "* State at time $t$  \n",
    "\n",
    "\\begin{equation}\n",
    "    \\boldsymbol{s}_t=f(\\boldsymbol{s}_{t-1}, y_{t-1}, \\mathbf{c}_t)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\boldsymbol{s}_{t-1}$ previous state of the decoder\n",
    "* $y_{t-1}$ previous output from the decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $c_t$ is a sum of hidden states of the input sequence, weighted by alignment scores\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathbf{c}_t &= \\sum_{i=1}^n \\alpha_{t,i} \\boldsymbol{h}_i & \\small{\\text{; Context vector for output }y_t}\\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Alignment Scores\n",
    "\n",
    "\\begin{aligned}\n",
    "\\alpha_{t,i} &= \\text{align}(y_t, x_i) & \\small{\\text{How well two words }y_t\\text{ and }x_i\\text{ are aligned}}\\\\\n",
    "&= \\frac{\\exp(\\text{score}(\\boldsymbol{s}_{t-1}, \\boldsymbol{h}_i))}{\\sum_{i'=1}^n \\exp(\\text{score}(\\boldsymbol{s}_{t-1}, \\boldsymbol{h}_{i'}))} & \\small{\\text{Softmax of some predefined alignment score}}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\text{score}(\\boldsymbol{s}_t, \\boldsymbol{h}_i) = \\mathbf{v}_a^\\top \\tanh(\\mathbf{W}_a[\\boldsymbol{s}_t; \\boldsymbol{h}_i])$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\mathbf{v}_a$ and $\\mathbf{W}_a$ are weight matrices to be learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results\n",
    "<img src=\"https://lilianweng.github.io/lil-log/assets/images/bahdanau-fig3.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image Captioning with Attention (Show Attend and Tell)\n",
    "![](http://kelvinxu.github.io/projects/diags/model_diag.png)\n",
    "[Xu et al., 2015](https://arxiv.org/abs/1502.03044)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://image.slidesharecdn.com/dlcv2017d3l6attentionmodels-170623173108/95/attention-models-d3l6-2017-upc-deep-learning-for-computer-vision-18-638.jpg?cb=1498239321\" width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Soft vs. Hard Attention\n",
    "<img src=\"data:image/png;base64,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\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Soft attention is a differentiable operation\n",
    "    * Can be trained with backpropagation\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Hard attention is not differentiable\n",
    "    * Must be trained with sampling techniques (reinforcement learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[This](https://stackoverflow.com/questions/35549588/soft-attention-vs-hard-attention/35852153#35852153) is a good explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pointer Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://nlp.seas.harvard.edu/images/the-annotated-transformer_0_0.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RNNs\n",
    "* Sequentially dependent\n",
    "* Attention over hidden states in time sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Transformer\n",
    "* Can be trained in parallel\n",
    "    * Only sequentially dependent at test time\n",
    "* Self attention over all inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformer\n",
    "\n",
    "<img src=\"http://nlp.seas.harvard.edu/images/the-annotated-transformer_14_0.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scaled Dot Product Attention\n",
    "\n",
    "<img src=\"http://nlp.seas.harvard.edu/images/the-annotated-transformer_33_0.png\">\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Self Attention\n",
    "\n",
    "Special case of **Scaled Dot Product Attention** where $Q=K=V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Positional Encoding\n",
    "                                                                                                    \n",
    "* In RNNs we know the location of items in a sequence base on how they are fed into the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because the transformer has no notion of time we need to help it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "| Positional Encoding  |  Sinusoids  |\n",
    "|---|---|\n",
    "|  <img src=\"https://timodenk.com/blog/wp-content/uploads/2019/01/transformer-architecture-pe-751x510.png\" width=300> |  <img src=\"http://nlp.seas.harvard.edu/images/the-annotated-transformer_49_0.png\" width=400> |\n",
    "\n",
    "\n",
    "* Every time-step add a combination of sinusoids telling the model where the input is relative to the begining of the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Turing Machines\n",
    "\n",
    "<img width = 400 src=\"https://rylanschaeffer.github.io/content/research/neural_turing_machine/ntm_architecture.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unsupervised Predictive Memory\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*vszusz3vAYGBpNwd8KI1pg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "[Attention? Attention!](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)  \n",
    "[Attention](https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-2-cf81bf32c73d)  \n",
    "[Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
