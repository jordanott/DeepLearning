{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from helper import visualization\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "figsize(15, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://github.com/jordanott/DeepLearning/blob/master/Figures/thanos_dl.jpg?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Overview\n",
    "* 7 Labs/Homeworks (25%)\n",
    "* Midterm (35%)\n",
    "    * In class handwritten test\n",
    "* Class Project (15%)\n",
    "* Final (25%)\n",
    "    * In class coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Materials\n",
    "* All homeworks available on [github](https://github.com/jordanott/DeepLearning)\n",
    "* Class website\n",
    "    * Office hours\n",
    "    * Schedule\n",
    "    * Links to resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If you have a question about homework\n",
    "    1. Google it\n",
    "    2. Ask a friend\n",
    "    3. Ask your mom\n",
    "    4. Post in the [github issues](https://github.com/jordanott/DeepLearning/issues)\n",
    "    5. Email me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# \"There's no such thing as a stupid question\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Except\n",
    "    * Bugs in code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* \"Will this be on the test?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A story goes that a Cambridge tutor in the mid-19th century once proclaimed: *\"I’m teaching the smartest boy in Britain.\"*  \n",
    "His colleague retorted: *\"I’m teaching the best test-taker.\"*  \n",
    "The first boy was James Clerk Maxwell. The second boy,\n",
    "who indeed scored highest on the Tripos, is long forgotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# My Trigger Words\n",
    "* Can you look at my code?\n",
    "* Will this be on the test?\n",
    "* That would be easy to do in MATLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advice for this class\n",
    "* Ask questions\n",
    "* Be comfortable being uncomfortable\n",
    "* Becoming profecient at deep learning requires failing a lot\n",
    "* Come to office hours\n",
    "* Practice on your own (more than just the homeworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CPSC: 370 Deep Learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* This class is about deep learning\n",
    "* Keras is one *tool* we will use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review\n",
    "* Machine Learning\n",
    "    * Supervised/unsupervised\n",
    "* Linear Regression\n",
    "    * Gradient Descent \n",
    "* Perceptrons\n",
    "    * Delta Rule\n",
    "* Multi Layer Perceptrons\n",
    "    * Backpropogation\n",
    "* Neural Networks\n",
    "    * Activation functions\n",
    "    * Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Map of Machine Learning\n",
    "<center><img src=\"https://i.pinimg.com/originals/6e/9b/dd/6e9bdde9d485fe2476738ab1733e8d49.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train-Test Split\n",
    "Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Train our model\n",
    "* 70% of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Check model performance during training\n",
    "    * Don't learn on this data!\n",
    "    * 20% of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Test once training is finished\n",
    "    * Don't learn on this data!\n",
    "    * 10% of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randn(100)\n",
    "\n",
    "x = np.arange(0,100) \n",
    "y = x + 5*noise\n",
    "\n",
    "plt.scatter(x, y); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train Test Split Code\n",
    "* 100 data samples\n",
    "* The $x$ is the input feature\n",
    "* The $y$ is the target \n",
    "* Split this into x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train,y_train, label='Train')\n",
    "plt.scatter(x_test,y_test, label='Test')\n",
    "plt.legend(); plt.plot(); None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Terminology\n",
    "<center><img src=\"https://djsaunde.files.wordpress.com/2017/07/bias-variance-tradeoff.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression\n",
    "* $N$ data points, each with $d$ features\n",
    "* Corresponding number of targets\n",
    "\n",
    "\\begin{align}\n",
    "    X &= \\begin{bmatrix}\n",
    "       x_{11} & ... & x_{1d} \\\\\n",
    "       x_{21} & ... & x_{2d}\\\\\n",
    "       \\vdots & \\vdots & \\vdots \\\\\n",
    "       x_{n1} & ... & x_{nd}\n",
    "     \\end{bmatrix} \n",
    "    &\n",
    "    Y &= \\begin{bmatrix}\n",
    "       y_{1} \\\\\n",
    "       y_{2} \\\\\n",
    "       \\vdots \\\\\n",
    "       y_{n}\n",
    "     \\end{bmatrix}\n",
    "   \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{align}\n",
    "    \\theta &= \\begin{bmatrix}\n",
    "       \\theta_{1} \\\\\n",
    "       \\theta_{2} \\\\\n",
    "       \\vdots \\\\\n",
    "       \\theta_{d} \n",
    "     \\end{bmatrix} \n",
    "   \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Train a model (classifier, predictor) to learn the target (output, true label) for the data\n",
    "* **INPUT:** Data, $X^{n\\times d}$, labels $Y^{n \\times c}$\n",
    "* **OUTPUT:** Model(x): $\\xrightarrow{}$ y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate weights\n",
    "theta = .1\n",
    "# multiply theta with x_train\n",
    "y_train_hat = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression Model\n",
    "* What do we want to minimize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Mean Squared error\n",
    "\\begin{equation}\n",
    "    J(\\theta) = \\frac{1}{2} (Y - \\hat{Y})^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MSE of y_train and y_train_hat\n",
    "J_theta = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plot initial prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train, label='Train')\n",
    "plt.plot(x_train, theta * x_train, label='$\\hat{Y}$')\n",
    "plt.title('$J = $' + str(J_theta)); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$\\theta$: Parameters, coefficients, or weights of the model  \n",
    "$Y$: True target value for input $X$  \n",
    "$\\hat{Y} = X\\theta$: Prediction from the model  \n",
    "$J(\\theta)$: Cost function in terms of $\\theta$. We say *\"in terms of\"* because $J$ is a function of $\\theta$ (i.e. as $\\theta$ changes, $J$ changes)  \n",
    "You may also see this. They're equivilant\n",
    "\\begin{equation}\n",
    "    J(\\theta) = \\frac{1}{2N} (Y - \\hat{Y})^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chain Rule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$g(x) = x^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$f(g) = 4z - 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\frac{d}{dx} f(g(x)) = f'(g(x)) g'(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\frac{df}{dx} = \\frac{df}{dg} \\frac{dg}{dx}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chain Rule with Machines\n",
    "|  Two Functions $f$ and $g$  | Composite Function $f \\circ g$  |\n",
    ":-------------------------:|:-------------------------:\n",
    "| <img src=\"https://mathinsight.org/media/image/image/function_machines_composed.png\" width=400> | <img src=\"https://mathinsight.org/media/image/image/function_machines_composed_combined.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://mathinsight.org/media/image/image/chain_rule_geometric_objects.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\frac{df}{dx} = \\frac{df}{dg} \\frac{dg}{dx}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[Khan Academy](https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/v/chain-rule-introduction)\n",
    "\n",
    "[Machines](https://mathinsight.org/chain_rule_idea)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training a Linear Regression Model\n",
    "* Closed form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "    \\theta = (X^T X)^{-1} X^T Y\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "   \\hat{Y} = X\\theta\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "   J(\\theta) = \\frac{1}{2} (Y - \\hat{Y})^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "   J(\\theta) = \\frac{1}{2} (Y - X\\theta)^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "   J(\\theta) = \\frac{1}{2} (Y - X\\theta)^T(Y - X\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "   \\frac{\\partial}{\\partial\\theta}J(\\theta) = \\frac{\\partial}{\\partial\\theta} (Y - X\\theta)^T(Y - X\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "   \\frac{\\partial}{\\partial\\theta}J(\\theta) = \\frac{\\partial}{\\partial\\theta} (Y^T Y - \\theta^T X^T X \\theta - 2Y^T X \\theta )\n",
    "\\end{equation}\n",
    "\n",
    "**Matrix Calculus Rules**\n",
    "\\begin{equation}\n",
    "   \\frac{\\partial \\theta^T A\\theta}{\\partial\\theta} = 2A^T \\theta\n",
    "   \\hspace{10mm}\n",
    "   \\frac{\\partial A\\theta}{\\partial\\theta} = A^T\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "   \\frac{\\partial}{\\partial\\theta}J(\\theta) = 0 - 2X^T X \\theta - 2 X^T Y \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "   \\frac{\\partial}{\\partial\\theta}J(\\theta) = 0 - 2X^T X \\theta - 2 X^T Y \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "   2X^T X \\theta = 2 X^T Y \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "   \\theta = (X^T X)^{-1} X^T Y \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Iterative Solution\n",
    "    * Look at the error for a single sample \n",
    "    \n",
    "\\begin{equation}\n",
    "   \\nabla_{\\theta}J(\\theta) = \\frac{1}{2N}\\sum_{i=1}^{N} \\nabla_{\\theta} (y_{i} - x_{i}\\theta)^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{align}\n",
    "\\nabla_{\\theta}J(\\theta) &= \\begin{bmatrix}\n",
    "   \\frac{\\partial J(\\theta)}{\\partial \\theta_{0}} \\\\\n",
    "   \\frac{\\partial J(\\theta)}{\\partial \\theta_{1}} \\\\\n",
    "   \\vdots \\\\\n",
    "   \\frac{\\partial J(\\theta)}{\\partial \\theta_{d}}\n",
    " \\end{bmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "   \\nabla_{\\theta} (y_{i} - x_{i}\\theta)^2 = - 2(y_{i} - x_{i}\\theta)x_{i}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Calculate Gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$J(\\theta) = \\nabla_{\\theta} \\frac{1}{2}(y - x\\theta)^2 = - \\frac{1}{N}\\sum_{i=1}^N (y_{i} - x_{i}\\theta)x_{i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_theta = \n",
    "update     = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\theta_{new} = \\theta - \\alpha \\nabla_{\\theta} J(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.0001\n",
    "new_theta = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualize Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train, label='Train')\n",
    "plt.plot(x_train, theta * x_train, label=r'$\\theta$')\n",
    "plt.plot(x_train, new_theta * x_train, label=r'New $\\theta$')\n",
    "\n",
    "plt.title('$J = $' + str(J_theta)); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "save_theta = [theta]\n",
    "J          = [J_theta]\n",
    "for i in range(7):\n",
    "    grad_theta = -(y_train - theta * x_train) * x_train\n",
    "    update     = np.sum(grad_theta) / float(x_train.shape[0])\n",
    "    theta      = theta - 0.0001 * update\n",
    "    \n",
    "    J.append(0.5*np.sum((y_train - theta * x_train)**2))\n",
    "    save_theta.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.scatter(x_train, y_train, label='Train')\n",
    "\n",
    "for i in range(7):\n",
    "    plt.plot(x_train, save_theta[i] * x_train, label=i)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(J); plt.title('J')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient Descent Algorithm\n",
    "**Input:** Training data $X,Y$, learning rate $\\alpha$  \n",
    "**Output:** Model parameters $\\theta$  \n",
    "\n",
    "* Init weights, $\\theta$  \n",
    "* For epoch in Epochs\n",
    "    * For x,y in X,Y  \n",
    "\n",
    "    \\begin{equation}\n",
    "        J(\\theta)\\gets J(\\theta) + \\frac{1}{2N} (y_{i} - x_{i}\\theta)^2\n",
    "    \\end{equation}\n",
    "    * $\\theta \\gets \\theta - \\alpha \\nabla_{\\theta} J(\\theta)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient Descent 1D  \n",
    "\n",
    "![](https://github.com/jordanott/DeepLearning/blob/master/Figures/gradient_descent_1d.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient Descent 2D\n",
    "\n",
    "![](https://github.com/jordanott/DeepLearning/blob/master/Figures/gradient_descent_2d.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The code for the above visuals can be found [here](https://github.com/jordanott/CPSC392/blob/master/Notebooks/Linear%20Regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization\n",
    "![](https://wendysbistudynotes.files.wordpress.com/2018/06/overfitting2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Regularization\n",
    "* Reduce the chance that our model overfits\n",
    "* Increase generalizability\n",
    "\n",
    "\\begin{equation}\n",
    "   J(\\theta) = \\frac{1}{2N} \\sum_{i=1}^{N}(y_{i} - x_{i}\\theta)^2 + \\text{Penalty}  \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L-Norm\n",
    "\\begin{equation}\n",
    "   ||\\theta||_p = (\\sum_{i=0}^{d} |\\theta_i|^p)^{\\frac{1}{p}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "   ||\\theta||_2 = (\\sum_{i=0}^{d} |\\theta_i|^2)^{\\frac{1}{2}} = \\sqrt{\\theta_0^2 + ... + \\theta_d^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L2 Norm\n",
    "* Penalize large weights even more $||\\theta_{j}||_2^2$ \n",
    "* How much we care about the penalty, $\\lambda$ \n",
    "\n",
    "\\begin{equation}\n",
    "    J(\\theta) = \\frac{1}{2N} \\sum_{i=1}^{N}(y_{i} - x_{i}\\theta)^2 + \\lambda \\sum_{j=0}^{d} \\theta_{j}^2  \n",
    "\\end{equation}\n",
    "\n",
    "* \"Shrink\" parameters towards zero \n",
    "* Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute l2 norm of theta\n",
    "l2_norm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L1 (Lasso) vs L2 (Ridge)\n",
    "![](https://cdn-images-1.medium.com/max/1580/1*o6H_R3Do1zpch-3MZk_fjQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Perceptrons\n",
    "![](https://appliedgo.net/media/perceptron/neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Perceptrons\n",
    "* Standard linear regression\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{y} = \\sum_{i=0}^{d} x_{i} \\theta_{i}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "    \\hat{y} = T(\\sum_{i=0}^{d} x_{i} \\theta_{i})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    T(z) = \\begin{cases}\n",
    "    1 & z > threshold  \\\\\n",
    "    0 & otherwise\n",
    "    \\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Boolean Functions (OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[0,0,0],[0,1,1],[1,0,1],[1,1,1]],columns=['x1','x2','y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['x1'],df['x2'],c=df['y'],s=100,cmap='Dark2'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Perceptron\n",
    "\\begin{equation}\n",
    "    \\hat{y} = T(\\sum_{i=0}^{d} x_{i} \\theta_{i})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    T(z) = \\begin{cases}\n",
    "    1 & z > threshold  \\\\\n",
    "    0 & otherwise\n",
    "    \\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "theta = np.random.normal(size=(2,1)) # randomly pick values for theta\n",
    "x = df[['x1','x2']].values           # inputs are x1 & x2\n",
    "\n",
    "np.dot(x, theta) > 0                 # linear combination of x & theta; threshold function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "visualization.plot_decision_boundary(df, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step Function\n",
    "![](https://qph.fs.quoracdn.net/main-qimg-d223b378c4b7b3edcb4d4f61607f6bca.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Perceptron Graph Model\n",
    "![](http://ataspinar.com/wp-content/uploads/2016/11/perceptron_schematic_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AND\n",
    "\n",
    "* Find the weights of a perceptron that satisfy AND\n",
    "\n",
    "| $X_1$ | $X_2$ | Y |\n",
    "| ----- |:-----:| -----:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 0 |\n",
    "| 1 | 0 | 0 |\n",
    "| 1 | 1 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Delta Rule\n",
    "* Goal: Update $\\theta$ to minimize error\n",
    "* $\\Delta \\theta$: small change in $\\theta$, \"weight update\"\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta = \\theta - \\Delta \\theta\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "    J(\\theta) = \\frac{1}{2}\\sum_{i=1}^{N} (y_{i} - X_{i}\\theta)^2 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\alpha$: learning rate\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Delta \\theta = - \\alpha \\sum_{i=1}^{N} (y_{i} - X_{i}\\theta ) X_{i}\n",
    "\\end{equation}\n",
    "\n",
    "What does this look like that we've seen before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "    \\Delta \\theta = \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta} = \\alpha \\frac{\\partial J(\\theta)}{\\partial \\delta} \\frac{\\partial \\delta}{\\partial \\theta}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# XOR\n",
    "\n",
    "* Find the weights of a perceptron that satisfy XOR\n",
    "\n",
    "| $X_1$ | $X_2$ | Y |\n",
    "| ----- |:-----:| -----:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 0 | 1 |\n",
    "| 1 | 1 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Not **linearly seperable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://img.itch.zone/aW1nLzEzNzk2MzQuanBn/original/b02c5u.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi Layer Perceptrons\n",
    "\n",
    "\\begin{align}\n",
    "    \\theta^{(1)} &= \\begin{bmatrix}\n",
    "       \\theta^{(1)}_{01} & ... & \\theta^{(1)}_{0h} \\\\\n",
    "       \\theta^{(1)}_{11} & ... & \\theta^{(1)}_{1h}\\\\\n",
    "       \\vdots & \\vdots & \\vdots \\\\\n",
    "       \\theta^{(1)}_{d1} & ... & \\theta^{(1)}_{dh}\n",
    "     \\end{bmatrix} \n",
    "     \\hspace{20mm}\n",
    "     \\theta^{(2)} &= \\begin{bmatrix}\n",
    "       \\theta^{(2)}_{01} & ... & \\theta^{(2)}_{0c} \\\\\n",
    "       \\theta^{(2)}_{11} & ... & \\theta^{(2)}_{1c}\\\\\n",
    "       \\vdots & \\vdots & \\vdots \\\\\n",
    "       \\theta^{(2)}_{h1} & ... & \\theta^{(2)}_{hc}\n",
    "     \\end{bmatrix}\n",
    " \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Draw the multilayer perceptron formed by:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{Y} = T(T(X\\theta^{(1)})\\theta^{(2)})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hidden Nodes\n",
    "\n",
    "\\begin{equation}\n",
    "    z_{j} = T(\\sum_{i=0}^{d}x_{i}\\theta^{(1)}_{ij})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Output Nodes\n",
    "\\begin{equation}\n",
    "    \\hat{Y}_j = T(\\sum_{i=0}^{h}z_{i}\\theta^{(2)}_{ij})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "* Instead of a threshold function, $T$, we use a nonlinear function, $\\phi$\n",
    "* $\\phi$: Activation function\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{Y} = \\phi_2(\\phi_1(X\\theta^{(1)})\\theta^{(2)})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "num_hidden_nodes = 5; num_output_nodes = 3\n",
    "x = np.random.randn(100,20)\n",
    "\n",
    "theta_1 = np.random.randn(20,num_hidden_nodes)\n",
    "theta_2 = np.random.randn(num_hidden_nodes, num_output_nodes)\n",
    "\n",
    "def phi(z): return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hidden Nodes\n",
    "\n",
    "\\begin{equation}\n",
    "    z_{j} = \\phi_1(\\sum_{i=0}^{d}x_{i}\\theta^{(1)}_{ij})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# compute z \n",
    "z = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Output Nodes\n",
    "\\begin{equation}\n",
    "    \\hat{Y}_j = \\phi_2(\\sum_{i=0}^{h}z_{i}\\theta^{(2)}_{ij})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_hat = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Activation Functions (Sigmoid)\n",
    "\n",
    "* Squashes numbers to range [0,1]\n",
    "* Historically popular because of relation to biology \n",
    "\n",
    "\\begin{equation}\n",
    "    \\phi (z) = \\frac{1}{1+e^{-z}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10); y = 1 / (1 + np.exp(-x))\n",
    "plt.plot(x,y); plt.title('Sigmoid'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Saturated neurons “kill” the gradients\n",
    "2. Sigmoid outputs are not zero-centered\n",
    "    * The gradients on $\\theta$ will be either all positive or all negative\n",
    "3. exp() is a bit compute expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Activation Functions (tanh)\n",
    "\n",
    "\\begin{equation}\n",
    "    \\phi (z) = tanh(z)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5); y = np.tanh(-x)\n",
    "\n",
    "plt.plot(x,y); plt.title('Tanh'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Activation Function (ReLU)\n",
    "* Rectified Linear Unit   \n",
    "\n",
    "\\begin{equation}\n",
    "    \\phi (z) = max(0, z)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5); y = np.maximum(0,x)\n",
    "\n",
    "plt.plot(x,y); plt.title('ReLU'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ReLU\n",
    "**Good**\n",
    "* Does not saturate (in positive region)\n",
    "* Very computationally efficient\n",
    "* Converges much faster than sigmoid/tanh in practice (e.g. 6x)\n",
    "* Actually more biologically plausible than sigmoid  \n",
    "\n",
    "**Bad**\n",
    "* Not zero-centered output\n",
    "* Gradient when $x < 0$ is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Activation Function (Leaky ReLU)\n",
    "\\begin{equation}\n",
    "    \\phi (z) = max(\\alpha z, z)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for alpha in np.linspace(0, 1, 11):\n",
    "    x = np.linspace(-5, 5); y = np.maximum(alpha*x,x)\n",
    "    plt.plot(x,y, label='$\\\\alpha$ = ' + str(round(alpha,1)))\n",
    "plt.legend(); plt.title('Leaky ReLU'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Does not saturate\n",
    "- Computationally efficient\n",
    "- Converges much faster than\n",
    "sigmoid/tanh in practice! (e.g. 6x)\n",
    "- will not “die”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning\n",
    "* We want to update weights to minimize error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* This was easy with one layer\n",
    "    * Targets are immediately available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* With many layers we must pass the error backwards\n",
    "    * Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forward Pass\n",
    "\n",
    "\\begin{equation}\n",
    "    Z^{(1)} = X^{(1)} \\theta^{(1)} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    X^{(2)} = \\phi_1 ( Z^{(1)} )\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    Z^{(2)} = X^{(2)} \\theta^{(2)} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{Y} = \\phi_2 ( Z^{(2)} )\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "\\begin{equation}\n",
    "    J(\\theta) = \\frac{1}{2}( Y - \\hat{Y} )^2\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "   \\frac{\\partial J}{\\partial \\theta^{(2)}} = \\frac{\\partial J}{\\partial \\hat{Y}} \\frac{\\partial \\hat{Y}}{\\partial Z^{(2)}} \\frac{\\partial Z^{(2)}}{\\partial \\theta^{(2)}} = (Y-\\hat{Y}) \\phi_2'(Z^{(2)}) X^{(2)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "    \\frac{\\partial J}{\\partial \\theta^{(1)}} = \\frac{\\partial J}{\\partial \\hat{Y}} \\frac{\\partial \\hat{Y}}{\\partial Z^{(2)}} \\frac{\\partial Z^{(2)}}{\\partial X^{(2)}} \\frac{\\partial X^{(2)}}{\\partial Z^{(1)}} \\frac{\\partial Z^{(1)}}{\\partial \\theta^{(1)}}\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation} \n",
    "    = (Y-\\hat{Y}) \\phi_2'(Z^{(2)}) \\theta^{(2)} \\phi_1'(Z^{(1)}) X^1\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='https://github.com/jordanott/DeepLearning/blob/master/Figures/dune.png?raw=true' width=1200>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Keras\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*OxAgYCBDKyXYLiWWUoKUcQ.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://irudnyts.github.io/images/posts/2017-10-20-custom-set-up-of-keras-and-tensorflow-for-r-and-python/r_python.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* R sucks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128 images in each batch\n",
    "batch_size = 128\n",
    "# 0-9 numbered images\n",
    "num_classes = 10\n",
    "# train for 20 steps\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://camo.githubusercontent.com/d440ac2eee1cb3ea33340a2c5f6f15a0878e9275/687474703a2f2f692e7974696d672e636f6d2f76692f3051493378675875422d512f687164656661756c742e6a7067\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the data\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Scale the data to be between 0 and 1\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# start building the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# add a fully connected layer\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# another one\n",
    "model.add(Dense(512, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# add last layer with activation for classification\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', # notice this isn't MSE because we're not doing regression\n",
    "    optimizer=SGD(),\n",
    "    metrics=['accuracy'])            # want to monitor accuracy over training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Built Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plotting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,                 # training data to learn from \n",
    "    batch_size=batch_size,            # size of batches\n",
    "    epochs=epochs,                    # how many iterations we train for \n",
    "    validation_data=(x_test, y_test)) # validation data to test on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['epochs'] = range(epochs)\n",
    "\n",
    "sns.lineplot(x='epochs', y='acc', data=history.history, label='Accuracy')\n",
    "sns.lineplot(x='epochs', y='val_acc', data=history.history, label='Val Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs'); plt.ylabel('Accuracy')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "[Code and detailed examples](https://github.com/jordanott/DeepLearning/blob/master/Notebooks/01%20Neural%20Networks%20Examples.ipynb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
